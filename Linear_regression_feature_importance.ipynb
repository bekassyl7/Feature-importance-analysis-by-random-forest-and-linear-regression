{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear_regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZJVtylVG5ku"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "import sklearn\n",
        "from sklearn import linear_model\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/gdrive/MyDrive/Colab Notebooks/MD_specimen_label_chart.xlsx - No El.csv\")\n",
        "dataset\n",
        "x = dataset[['T', 't', 'TS', 'YS', 'HT']]\n",
        "y = dataset['RA']\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 100)\n",
        "mlr = linear_model.LinearRegression()\n",
        "mlr.fit(x_train, y_train)\n",
        "print(\"Intercept: \", mlr.intercept_)\n",
        "print(\"Coefficients:\")\n",
        "list(zip(x, mlr.coef_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5sXSLNIbzBk",
        "outputId": "fc8d3b85-7f97-4a8b-d000-85f290511441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intercept:  242.3774863899571\n",
            "Coefficients:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('T', 0.20154820848689303),\n",
              " ('t', -0.03978573452406045),\n",
              " ('TS', -0.6507627244111011),\n",
              " ('YS', 0.38184919096861725),\n",
              " ('HT', 1.484139322276089)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('R squared: {:.2f}'.format(mlr.score(x_train,y_train)*100))"
      ],
      "metadata": {
        "id": "Y2H6VdgacSpf",
        "outputId": "373c7420-a5f6-48ff-cd36-94ae57d1c0c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R squared: 77.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_mlr= mlr.predict(x_test)\n",
        "from sklearn import metrics\n",
        "meanAbErr = metrics.mean_absolute_error(y_test, y_pred_mlr)\n",
        "meanSqErr = metrics.mean_squared_error(y_test, y_pred_mlr)\n",
        "rootMeanSqErr = np.sqrt(metrics.mean_squared_error(y_test, y_pred_mlr))\n",
        "print('R squared: {:.2f}'.format(mlr.score(x,y)*100))\n",
        "print('Mean Absolute Error:', meanAbErr)\n",
        "print('Mean Square Error:', meanSqErr)\n",
        "print('Root Mean Square Error:', rootMeanSqErr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM21orzpFani",
        "outputId": "1545c016-8617-4166-d7b6-83bea398d24f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R squared: 41.01\n",
            "Mean Absolute Error: 12.051801795895775\n",
            "Mean Square Error: 204.70842088402733\n",
            "Root Mean Square Error: 14.307635055592778\n"
          ]
        }
      ]
    }
  ]
}